# Configuration file for the "Inferential" web app. Specifies models, their backends, and the logo used in the application.

models:
  - name: LaMini-Flan-T5-248M
    hf_path: jncraton/LaMini-Flan-T5-248M-ct2-int8
    backend: ctranslate2
    max_prompt_length: 250
    prompts: 
  - name: LaMini-GPT-124M
    hf_path: jncraton/LaMini-GPT-124M-ct2-int8
    backend: ctranslate2
    max_prompt_length: 250
    prompts: 
  - name: gpt2
    hf_path: marella/gpt-2-ggml
    backend: ctransformers
    max_prompt_length: 250
    prompts: This is a lightweight model, which will not answer questions, but instead continue writing sentences you say like it is part of a story.
# Example vllm config
#  - name: neural-chat-7B-v3
#    hf_path: TheBloke/neural-chat-7B-v3-1-AWQ
#    backend: vllm
#    url: http://localhost:8000/generate
#    max_prompt_length: 250

# When changing the logo, be sure to resize it to 30px by 30px for the best quality
logo: /static/logos/default.png
